{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_images, return_stacks_per_position_id, make_isotropic, extract_nuclei_labels, measure_intensity\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directory (folder containing the subfolders storing your images)\n",
    "data_folder = Path(\"./raw_data\")\n",
    "\n",
    "# Define the scaling in x, y and z.\n",
    "scaling_x_um = 0.342\n",
    "scaling_y_um = 0.342\n",
    "scaling_z_um = 0.663\n",
    "\n",
    "# Define the analysis parameters\n",
    "top_hat_radius = 5\n",
    "gaussian_sigma = 2\n",
    "voronoi_otsu_spot_sigma = 10\n",
    "voronoi_otsu_outline_sigma = 1\n",
    "closing_labels_radius = 5\n",
    "erosion_labels_radius = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:30<00:00,  7.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store subfolder names\n",
    "subfolder_list = []\n",
    "\n",
    "# Iterate over subdirectories in the parent folder\n",
    "for subfolder in data_folder.iterdir():\n",
    "    if subfolder.is_dir():\n",
    "        subfolder_list.append(subfolder.name)\n",
    "\n",
    "# Initialize an empty list to store per folder_id dataframes\n",
    "folder_dataframes = []\n",
    "\n",
    "for folder in tqdm(subfolder_list):\n",
    "    \n",
    "    # Build the path containing the input images\n",
    "    data_path = data_folder.joinpath(folder)\n",
    "    \n",
    "    # Add the intermediate crop subdirectory\n",
    "    data_path = data_path.joinpath('Crop')\n",
    "    \n",
    "    # Retrieve the paths of all the images within data_path (ignoring ch02, brightfield channel)\n",
    "    images_per_position = read_images(data_path)\n",
    "\n",
    "    # Initialize an empty list to store per position_id dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    for position_id, files in images_per_position.items():\n",
    "        \n",
    "        # Retrieve the paths of all the images within data_path (ignoring ch02, brightfield channel)\n",
    "        images_per_position = read_images(data_path)\n",
    "\n",
    "        # Generate the ch00_stack (nuclei) and ch01_stack (protein of interest) from the individual slices \n",
    "        ch00_stack, ch01_stack = return_stacks_per_position_id(images_per_position, position_id)\n",
    "\n",
    "        # Extract the nuclei labels from the ch00_stack\n",
    "        nuclei_labels = extract_nuclei_labels(ch00_stack, \n",
    "                                scaling_x_um, \n",
    "                                scaling_y_um, \n",
    "                                scaling_z_um, \n",
    "                                top_hat_radius, \n",
    "                                gaussian_sigma, \n",
    "                                voronoi_otsu_spot_sigma,\n",
    "                                voronoi_otsu_outline_sigma,\n",
    "                                closing_labels_radius,\n",
    "                                erosion_labels_radius)\n",
    "\n",
    "        # Rescale the ch01_stack (protein of interest) to make data isotropic in order to include it as intensity_image \n",
    "        marker_resampled = make_isotropic(ch01_stack, scaling_x_um, scaling_y_um, scaling_z_um)\n",
    "\n",
    "        # Extract intensity stats on a per nucleus basis\n",
    "        df = measure_intensity(nuclei_labels, marker_resampled)\n",
    "\n",
    "        # Insert position_id into the dataframe\n",
    "        df.insert(0, 'position_id', position_id)\n",
    "\n",
    "        # Append the per_position df to the dataframes list\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames in the list\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Insert folder_id into the dataframe\n",
    "    concatenated_df.insert(0, 'folder_id', folder)\n",
    "\n",
    "    # Append the per folder_id dataframe to the folder_dataframes list\n",
    "    folder_dataframes.append(concatenated_df)\n",
    "    \n",
    "final_df = pd.concat(folder_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the final results into a .csv file\n",
    "final_df.to_csv('./results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_organoids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
